# ===========================================
# IntelliFile Backend - Environment Configuration
# ===========================================
# Copy this file to .env and customize as needed

# ===========================================
# Application Settings
# ===========================================
DEBUG=True
APP_NAME="IntelliFile"
APP_VERSION="1.0.0"

# ===========================================
# Server Settings
# ===========================================
HOST=0.0.0.0
PORT=8000

# ===========================================
# Ollama/LLM Settings
# ===========================================
# For local development:
OLLAMA_BASE_URL=http://localhost:11434
# For Docker:
# OLLAMA_BASE_URL=http://ollama:11434

OLLAMA_MODEL=llama3.1:latest
OLLAMA_TIMEOUT=120

# ===========================================
# Embedding Settings
# ===========================================
EMBEDDING_MODEL=all-MiniLM-L6-v2
# Use "cpu" for CPU-only, "cuda" for GPU
EMBEDDING_DEVICE=cpu

# ===========================================
# RAG Pipeline Settings
# ===========================================
CHUNK_SIZE=400
CHUNK_OVERLAP=50
TOP_K_RESULTS=5

# ===========================================
# File Upload Settings
# ===========================================
# Maximum file size in bytes (50MB)
MAX_FILE_SIZE=52428800
